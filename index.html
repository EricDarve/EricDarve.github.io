<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8' />
    <meta http-equiv="X-UA-Compatible" content="chrome=1" />
    <meta name="description" content="CME 213 Introduction to parallel computing" />

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">    

    <link href="https://www.stanford.edu/su-identity/css/su-identity.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,700" rel="stylesheet" type="text/css">
    <!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <!--[if IE 8]>
      <link rel="stylesheet" type="text/css" href="https://www.stanford.edu/su-identity/css/ie/ie8.css" />
    <![endif]-->
    <!--[if IE 7]>
      <link rel="stylesheet" type="text/css" href="https://www.stanford.edu/su-identity/css/ie/ie7.css" />
    <![endif]-->     

    <title>CME213 Stanford Parallel Computing Class</title>

  </head>

  <body>

    <!-- Brandbar snippet start -->
    <div id="brandbar">
      <div class="container">
        <a href="http://www.stanford.edu">
          <img src="https://www.stanford.edu/su-identity/images/brandbar-stanford-logo@2x.png" alt="Stanford University" width="153" height="22">
        </a>
      </div> <!-- .container end -->
    </div> <!-- #brandbar end -->
    <!-- Brandbar snippet end -->    

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/EricDarve/cme213_material_2013">View on GitHub</a>

          <h1 id="project_title">CME 213 Introduction to parallel computing using MPI, openMP, and CUDA</h1>
          <h2 id="project_tagline">Eric Darve, Stanford University</h2>

        </header>
    </div>

    <!-- MAIN CONTENT -->

    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">    

    <a href="http://explorecourses.stanford.edu/search?view=catalog&q=cme213"><strong>CME 213, Stanford University, Spring 2013</strong></a>

    <br>

    You can download all the material for this class by going to the <a href=https://github.com/EricDarve/cme213_material_2013>GitHub repository</a>. The command to clone the site is simply:
<pre><code>$ git clone https://github.com/EricDarve/cme213_material_2013.git
</code></pre>

    <br>

    <strong>Instructors:</strong>

    <br>

    <a href=http://engineering.stanford.edu/profile/darve>Eric Darve</a>, <a href=http://icme.stanford.edu/>Stanford University</a>

    <br> 

    <a href=http://www.linkedin.com/pub/erich-elsen/51/15a/6b1>Erich Elsen</a>, <a href=http://www.royal-caliber.com/>Royal Caliber</a>

    <br>

    <a href=https://github.com/myssa89>Sammy El Ghazzal</a>

    <br><br>

    Contact: Eric Darve, <a href="mailto:darve@stanford.edu?Subject=CME213%20GitHub%20web%20site">darve@stanford.edu</a>

    <br><br>

In the <a href=https://github.com/EricDarve/cme213_material_2013>GitHub repository</a>, you will find:
<ul>
  <li><a href="https://github.com/EricDarve/cme213_material_2013/tree/master/Lecture%20Slides">Lecture slides</a>.</li>
  <li><a href="https://github.com/EricDarve/cme213_material_2013/tree/master/Homework">Homeworks</a>. There are 6 homeworks divided as follows:
    <ol>
      <li><a href="https://github.com/EricDarve/cme213_material_2013/blob/master/Homework/Homework%20Pre-Requisites/Prerequisite%20Homework.pdf?raw=true">C++ pre-requisites</a></li>
      <li><a href="https://github.com/EricDarve/cme213_material_2013/blob/master/Homework/Homework%201%20OpenMP/Homework%201.pdf?raw=true">OpenMP</a></li>
      <li><a href="https://github.com/EricDarve/cme213_material_2013/blob/master/Homework/Homework%202%20CUDA/Homework%202.pdf?raw=true">CUDA 1</a>: basic string shift algorithm and pagerank algorithm</li>
      <li><a href="https://github.com/EricDarve/cme213_material_2013/blob/master/Homework/Homework%203%20CUDA/Homework%203.pdf?raw=true">CUDA 2</a>: 2D heat diffusion</li>
      <li><a href="https://github.com/EricDarve/cme213_material_2013/blob/master/Homework/Homework%204%20CUDA/Homework%204.pdf?raw=true">CUDA 3</a>: Vigen&egrave;re cypher</li>
      <li><a href="https://github.com/EricDarve/cme213_material_2013/blob/master/Homework/Homework%205%20MPI/Homework%205.pdf?raw=true">MPI</a>: 2D heat diffusion</li>
    </ol>
  <li><a href="https://github.com/EricDarve/cme213_material_2013/tree/master/Final%20Project">Final Project</a>. The final project is about writing a CUDA code to calculate <a href="http://en.wikipedia.org/wiki/Connected-component_labeling">connected components</a> in images.</li> 
  <li><a href="https://github.com/EricDarve/cme213_material_2013/tree/master/Sample%20Code/CUDA">CUDA sample codes</a>.</li>
  <li><a href="https://github.com/EricDarve/cme213_material_2013/tree/master/Sample%20Code/MPI">MPI sample codes</a>.</li>   
</ul>
Recommended reading for this class:
<ul>
  <li><a href="http://www.amazon.com/Parallel-Programming-Multicore-Cluster-ebook/dp/B00D9KEL26/ref=sr_1_2?ie=UTF8&qid=1371080011&sr=8-2&keywords=Parallel+Programming+for+Multicore+and+Cluster+Systems">Parallel Programming for Multicore and Cluster Systems</a>, Rauber
and R&uuml;nger.</li>
  <li><a href="http://www.amazon.com/Introduction-Parallel-Computing-2nd-Edition/dp/0201648652/ref=sr_1_cc_1?s=aps&ie=UTF8&qid=1371080057&sr=1-1-catcorr&keywords=Introduction+to+Parallel+Computing">Introduction to Parallel Computing</a>, Grama, Gupta, Karypis, Kumar.</li>
  <li><a href="http://www.amazon.com/An-Introduction-Parallel-Programming-ebook/dp/B004IPPIP0/ref=sr_1_1?s=digital-text&ie=UTF8&qid=1371080057&sr=1-1&keywords=Introduction+to+Parallel+Computing">Introduction to Parallel Programming</a>, Pacheco.</li>
  <li><a href="http://www.amazon.com/Using-OpenMP-Programming-Engineering-Computation/dp/0262533022/ref=sr_1_1?s=books&ie=UTF8&qid=1371080174&sr=1-1&keywords=Using+OpenMP%3A+Portable+Shared+Memory+Parallel+Programming">Using OpenMP: Portable Shared Memory Parallel Programming</a>,
Chapman, Jost, van der Pas.</li>
  <li><a href="http://www.amazon.com/Parallel-Programming-OpenMP-Rohit-Chandra/dp/1558606718/ref=sr_1_1?s=books&ie=UTF8&qid=1371080208&sr=1-1&keywords=Parallel+Programming+in+OpenMP">Parallel Programming in OpenMP</a>, Chandra, Menon, Dagum, Kohr, Maydan, McDonald</li>
  <li><a href="http://www.amazon.com/Art-Multiprocessor-Programming-Revised-Reprint/dp/0123973376/ref=sr_1_1?s=books&ie=UTF8&qid=1371080254&sr=1-1&keywords=The+Art+of+Multiprocessor+Programming">The Art of Multiprocessor Programming</a>, Herlihy, Shavit.</li>
  <li><a href="http://www.amazon.com/CUDA-Example-Introduction-General-Purpose-Programming/dp/0131387685/ref=sr_1_1?s=books&ie=UTF8&qid=1371080279&sr=1-1&keywords=CUDA+by+Example%3A+An+Introduction+to+General-Purpose+GPU+Programming">CUDA by Example: An Introduction to General-Purpose GPU
Programming</a>, Sanders, Kandrot</li>
  <li><a href="http://www.amazon.com/CUDA-Handbook-Comprehensive-Guide-Programming/dp/0321809467/ref=sr_1_1?s=books&ie=UTF8&qid=1371080319&sr=1-1&keywords=CUDA+Handbook%3A+A+Comprehensive+Guide+to+GPU+Programming">CUDA Handbook: A Comprehensive Guide to GPU Programming</a>, Wilt</li>
</ul>


<h2><div id="slides">Lecture Slides</div></h2>

You can find the <a href="https://github.com/EricDarve/cme213_material_2013/tree/master/Lecture%20Slides">lecture slides</a> on GitHub.

<br>

List of topics:
<ul>
<li><a href="#pthreads">Pthreads</a></li>
<li><a href="#omp">OpenMP</a></li>
<li><a href="#cuda">CUDA</a></li>
<li><a href="#nvidia">NVIDIA CUDA Lectures</a></li>
<li><a href="#mpi">MPI</a></li>
</ul>

<h3><div id="pthreads"><a href="https://github.com/EricDarve/cme213_material_2013/blob/master/Lecture%20Slides/Pthreads/Lecture%201.pdf?raw=true">Lecture 1</a></div></h3>

<p><div id="topic">Topics:</div> introduction; syllabus; why we need parallelism; example of parallel program: summing up numbers</p>

<p>Shared memory and multicore processors</p>

<p>Introduction to <strong>Pthreads</strong></p>

<h3><a href="https://github.com/EricDarve/cme213_material_2013/blob/master/Lecture%20Slides/Pthreads/Lecture%202.pdf?raw=true">Lecture 2</a></h3>

<p><div id="topic">Topics:</div> <strong>Pthreads</strong>; creating and joining threads; example: multiplication of two matrices; Mutexes; example: dot product</p>

<h3><a href="https://github.com/EricDarve/cme213_material_2013/blob/master/Lecture%20Slides/OpenMP/Lecture%203.pdf?raw=true">Lecture 3</a></h3>

<p><div id="topic">Topics:</div> condition variables; example of a pizza restaurant and delivery; example with code sample
</p>

<p><strong>OpenMP</strong>; introduction; parallel regions
</p>

<h3><div id="omp"><a href="https://github.com/EricDarve/cme213_material_2013/blob/master/Lecture%20Slides/OpenMP/Lecture%204.pdf?raw=true">Lecture 4</a></div></h3>

<p><div id="topic">Topics:</div> <strong>OpenMP</strong>; parallel for loops; matrix multiplication; sections; single; tasks; master; critical; barrier; atomic; data sharing attributes; reduction clause
</p>

<h3><a href="https://github.com/EricDarve/cme213_material_2013/blob/master/Lecture%20Slides/OpenMP/Lecture%205.pdf?raw=true">Lecture 5</a></h3>

<p><div id="topic">Topics:</div> fast multipole method; <strong>OpenMP</strong> and <strong>Pthreads</strong> implementations
</p>

<h3><div id="cuda"><a href="https://github.com/EricDarve/cme213_material_2013/blob/master/Lecture%20Slides/CUDA/Lecture%206.pdf?raw=true">Lecture 6</a></div></h3>

<p><div id="topic">Topics:</div> <strong>CUDA</strong>; threading model, basic commands, simple example programs, threads, blocks; timing; basic debugging techniques / printf / how nvcc works; unary function using templates
</p>

<h3><a href="https://github.com/EricDarve/cme213_material_2013/blob/master/Lecture%20Slides/CUDA/Lecture%207.pdf?raw=true">Lecture 7</a></h3>

<p><div id="topic">Topics:</div> warps; coalescing and performance impact; caching; shared memory; bank conflicts; example of matrix transpose
</p>

<h3><a href="https://github.com/EricDarve/cme213_material_2013/blob/master/Lecture%20Slides/CUDA/Lecture%208.pdf?raw=true">Lecture 8</a></h3>

<p><div id="topic">Topics:</div> reduce and scan algorithms; Work complexity vs. step complexity.</p>

<p>Students were asked to group in team and find an efficient procedure to quickly add many numbers, and calculate a scan.
</p>

<p>There are no slides for this lecture.</p>

<h3><a href="https://github.com/EricDarve/cme213_material_2013/blob/master/Lecture%20Slides/CUDA/Lecture%209.pdf?raw=true">Lecture 9</a></h3>

<p><div id="topic">Topics:</div> <strong>CUDA</strong>; reduction algorithm; warp; thread-block; use of atomics
</p>

<h3><a href="https://github.com/EricDarve/cme213_material_2013/blob/master/Lecture%20Slides/CUDA/Lecture%2010.pdf?raw=true">Lecture 10</a></h3>

<p><div id="topic">Topics:</div> floating point numbers; matrix-vector products; how to optimize the memory access; study of different cases: small and large matrices; tall and fat matrices
</p>

<h3><a href="https://github.com/EricDarve/cme213_material_2013/blob/master/Lecture%20Slides/CUDA/Lecture%2011.pdf?raw=true">Lecture 11</a></h3>

<p><div id="topic">Topics:</div> discussion of <strong>Thrust</strong>; segmented algorithms; examples of problems that can be broken into Thrust algorithms
</p>

<h3><div id="nvidia"><a href="https://github.com/EricDarve/cme213_material_2013/blob/master/Lecture%20Slides/NVIDIA/Lecture%2012%20Streams%20and%20Concurrency.pdf?raw=true">Lecture 12</a></div></h3>

<p><strong>Steve Rennich from NVIDIA.</strong> Introduction to streams; increasing the concurrency; running concurrently memory transfers and kernels
</p>

<h3><div id="nvidia"><a href="https://github.com/EricDarve/cme213_material_2013/blob/master/Lecture%20Slides/NVIDIA/Lecture%2013%20OpenACC.pdf?raw=true">Lecture 13</a></h3>

<p><strong>Justin Luitjens from NVIDIA.</strong> OpenACC
</p>

<h3><div id="nvidia"><a href="https://github.com/EricDarve/cme213_material_2013/blob/master/Lecture%20Slides/NVIDIA/Lecture%2014%20CUDA%20Profiler.pdf?raw=true">Lecture 14</a></h3>

<p><strong>David Goodwin from NVIDIA.</strong> The CUDA nvvp profiler.
</p>

<h3><div id="nvidia"><a href="https://github.com/EricDarve/cme213_material_2013/blob/master/Lecture%20Slides/NVIDIA/Lecture%2015%20Sean%20Baxter%20Load%20balancing%20search.pdf?raw=true">Lecture 15</a></h3>

<p><strong>Sean Baxter from NVIDIA.</strong> Merge in merge-sort algorithms; merge-like operations. Load-balancing search.
</p>

<h3><div id="mpi"><a href="https://github.com/EricDarve/cme213_material_2013/blob/master/Lecture%20Slides/MPI/Lecture%2016.pdf?raw=true">Lecture 16</a></div></h3>

<p><div id="topic">Topics:</div> <strong>MPI</strong>; introduction to message-passing; point-to-point communication.
</p>

<h3><a href="https://github.com/EricDarve/cme213_material_2013/blob/master/Lecture%20Slides/MPI/Lecture%2017.pdf?raw=true">Lecture 17</a></h3>

<p><div id="topic">Topics:</div> deadlocks; blocking vs non-blocking; synchronous vs non-synchronous; introduction to collective communication
</p>

<h3><a href="https://github.com/EricDarve/cme213_material_2013/blob/master/Lecture%20Slides/MPI/Lecture%2018.pdf?raw=true">Lecture 18</a></h3>

<p><div id="topic">Topics:</div> collective communication; matrix-vector product; groups, communicators
</p>

<h3><a href="https://github.com/EricDarve/cme213_material_2013/blob/master/Lecture%20Slides/MPI/Lecture%2019.pdf?raw=true">Lecture 19</a></h3>

<p><div id="topic">Topics:</div> virtual topologies; application to matrix-vector product with 2D partitioning; introduction to performance metrics; speed-up, efficiency; Amdahl’s law
</p>

<h3><a href="https://github.com/EricDarve/cme213_material_2013/blob/master/Lecture%20Slides/MPI/Lecture%2020.pdf?raw=true">Lecture 20</a></h3>

<p><div id="topic">Topics:</div> performance metrics; example: dot-product; efficiency and iso-efficiency; matrix-vector product with 1D and 2D partitioning; matrix-matrix products; Cannon and DNS algorithms.
</p>

      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p><a href="http://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
